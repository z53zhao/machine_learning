{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Assignment-for-Module-6\" data-toc-modified-id=\"Assignment-for-Module-6-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Assignment for Module 6</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Getting-the-data-for-the-assignment-(similar-to-the-notebook-from-chapter-2-of-Hands-On...)\" data-toc-modified-id=\"Getting-the-data-for-the-assignment-(similar-to-the-notebook-from-chapter-2-of-Hands-On...)-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)</a></span></li></ul></li><li><span><a href=\"#Fix-the-categories-in-the-categorical-variable\" data-toc-modified-id=\"Fix-the-categories-in-the-categorical-variable-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Fix the categories in the categorical variable</a></span></li><li><span><a href=\"#Add-2-more-features\" data-toc-modified-id=\"Add-2-more-features-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Add 2 more features</a></span></li><li><span><a href=\"#Fix-missing-data\" data-toc-modified-id=\"Fix-missing-data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Fix missing data</a></span></li><li><span><a href=\"#Create-dummy-variables-based-on-the-categorical-variable\" data-toc-modified-id=\"Create-dummy-variables-based-on-the-categorical-variable-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Create dummy variables based on the categorical variable</a></span></li><li><span><a href=\"#Check-the-data\" data-toc-modified-id=\"Check-the-data-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Check the data</a></span></li><li><span><a href=\"#Partition-into-train-and-test\" data-toc-modified-id=\"Partition-into-train-and-test-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Partition into train and test</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Features</a></span></li><li><span><a href=\"#Scaling-features\" data-toc-modified-id=\"Scaling-features-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Scaling features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparing-models\" data-toc-modified-id=\"Comparing-models-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Comparing models</a></span></li></ul></li><li><span><a href=\"#Linear-regression-on-original-features-(no-transformations)-----benchmark\" data-toc-modified-id=\"Linear-regression-on-original-features-(no-transformations)-----benchmark-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Linear regression on original features (no transformations) --- benchmark</a></span></li><li><span><a href=\"#1.-Support-Vector-Machines-for-Regression\" data-toc-modified-id=\"1.-Support-Vector-Machines-for-Regression-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>1. Support Vector Machines for Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#(a)-In-this-exercise-your-goal-is-to-tune-SVR-with-FBR-kernel,-and-make-the-average-score-mean_squared_error-over-3-folds-(cv=3)-below-58000.\" data-toc-modified-id=\"(a)-In-this-exercise-your-goal-is-to-tune-SVR-with-FBR-kernel,-and-make-the-average-score-mean_squared_error-over-3-folds-(cv=3)-below-58000.-1.10.1\"><span class=\"toc-item-num\">1.10.1&nbsp;&nbsp;</span>(a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000.</a></span></li></ul></li><li><span><a href=\"#Performance-on-Test-Set\" data-toc-modified-id=\"Performance-on-Test-Set-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Performance on Test Set</a></span></li><li><span><a href=\"#2.-SVM-for-Classification\" data-toc-modified-id=\"2.-SVM-for-Classification-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>2. SVM for Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-target-variable\" data-toc-modified-id=\"Binary-target-variable-1.12.1\"><span class=\"toc-item-num\">1.12.1&nbsp;&nbsp;</span>Binary target variable</a></span></li><li><span><a href=\"#Linear-SVM-for-classification\" data-toc-modified-id=\"Linear-SVM-for-classification-1.12.2\"><span class=\"toc-item-num\">1.12.2&nbsp;&nbsp;</span>Linear SVM for classification</a></span></li></ul></li><li><span><a href=\"#(a)-Does-SVC-(with-default-hyper-parameters)-improve-the-performance-of-the-linear-SVM?\" data-toc-modified-id=\"(a)-Does-SVC-(with-default-hyper-parameters)-improve-the-performance-of-the-linear-SVM?-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>(a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?</a></span></li><li><span><a href=\"#(b)-Use-randomized-search-to-tune-hyper-parameters-of-SVC-and-improve-its-performance\" data-toc-modified-id=\"(b)-Use-randomized-search-to-tune-hyper-parameters-of-SVC-and-improve-its-performance-1.14\"><span class=\"toc-item-num\">1.14&nbsp;&nbsp;</span>(b) Use randomized search to tune hyper-parameters of SVC and improve its performance</a></span></li><li><span><a href=\"#(c)-Train-a-Logistic-Regression-(search-teh-best-hyper-parameters)-and-compare-its-performance-with-SVC\" data-toc-modified-id=\"(c)-Train-a-Logistic-Regression-(search-teh-best-hyper-parameters)-and-compare-its-performance-with-SVC-1.15\"><span class=\"toc-item-num\">1.15&nbsp;&nbsp;</span>(c) Train a Logistic Regression (search teh best hyper-parameters) and compare its performance with SVC</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment for Module 6\n",
    "\n",
    "In this assignment you will continue working with the housing price per district from the previous module assignment, this time training SVM models, both for regression and classification.\n",
    "\n",
    "#### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the categories in the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
    "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 2 more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables based on the categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
    "housing = housing.drop('ocean_proximity', axis=1)\n",
    "housing = housing.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 16 columns):\n",
      "longitude                   20640 non-null float64\n",
      "latitude                    20640 non-null float64\n",
      "housing_median_age          20640 non-null float64\n",
      "total_rooms                 20640 non-null float64\n",
      "total_bedrooms              20640 non-null float64\n",
      "population                  20640 non-null float64\n",
      "households                  20640 non-null float64\n",
      "median_income               20640 non-null float64\n",
      "median_house_value          20640 non-null float64\n",
      "rooms_per_household         20640 non-null float64\n",
      "population_per_household    20640 non-null float64\n",
      "INLAND                      20640 non-null uint8\n",
      "ISLAND                      20640 non-null uint8\n",
      "LESS_1H_OCEAN               20640 non-null uint8\n",
      "NEAR_BAY                    20640 non-null uint8\n",
      "NEAR_OCEAN                  20640 non-null uint8\n",
      "dtypes: float64(11), uint8(5)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition into train and test\n",
    "\n",
    "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
    "\n",
    "You can use the 70% for training set as both training and validation by using cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'median_house_value'\n",
    "features = list(train_set.columns)\n",
    "features = [f for f in features if f!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_set[features]\n",
    "y_tr = train_set[[target]]\n",
    "\n",
    "X_te = test_set[features]\n",
    "y_te = test_set[[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression on original features (no transformations) --- benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
      "Mean: 68945.88375656874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Support Vector Machines for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) In this exercise your goal is to tune SVR with FBR kernel, and make the average score mean_squared_error over 3-folds (cv=3) below 58000. \n",
    "\n",
    "You are encouraged to try optimizing any of the hyper-parameters of SVR\n",
    "\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html for more details\n",
    "\n",
    "However, as a hint, you can focus on C and gamma. \n",
    "\n",
    "Hint 2: if when you try different values for a hyper-parameter, the optimal models corresponds to one of the extreme values in your range, that probably means you can keep improving your solution by considering values beyond the current range.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [110000, 120000], 'gamma': [0.1, 0.15]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "C_vals = [110000, 120000] ## YOUR VALUES FOR C ##\n",
    "gamma_vals = [0.1, 0.15] ## YOUR VALUES FOR gamma ## \n",
    "\n",
    "param_grid = [{'C':C_vals, 'gamma':gamma_vals}]\n",
    "grid_search_rbf = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=3,scoring='neg_mean_squared_error')\n",
    "grid_search_rbf.fit(X_tr, np.ravel(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 120000, 'gamma': 0.15}\n",
      "56373.26669949688\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rbf.best_params_)\n",
    "print(np.sqrt(-grid_search_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55447.65998288715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search_rbf.best_estimator_   ## THIS SHOULD BE THE BEST GRID_SEARCH ##\n",
    "\n",
    "y_te_estimation = final_model.predict(X_te)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. SVM for Classification\n",
    "\n",
    "Now we transform the continuous target into a binary variable, indicating whether or not the price is above the average $179700\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179700.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(housing[['median_house_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_b = 1*np.ravel(y_tr>=179700.0)\n",
    "y_te_b = 1*np.ravel(y_te>=179700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = LinearSVC(random_state=42)\n",
    "lin_clf.fit(X_tr, y_tr_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384551495016611"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lin_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Does SVC (with default hyper-parameters) improve the performance of the linear SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866140642303433"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC(random_state=42)\n",
    "svc_clf.fit(X_tr, y_tr_b)\n",
    "y_pred = svc_clf.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes, it does. The SVC improves the performance as the accuracy score is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Use randomized search to tune hyper-parameters of SVC and improve its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import reciprocal, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95812569213732"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_rdn = reciprocal(20, 20000) \n",
    "gamma_rdn = uniform(loc=0, scale=4)\n",
    "\n",
    "param_grid_rdn = {'C':C_rdn, 'gamma':gamma_rdn}\n",
    "rdn_search = RandomizedSearchCV(SVC(kernel='rbf'), param_grid_rdn,\n",
    "                                n_iter=10, cv=5, scoring='accuracy',\n",
    "                                random_state=42)\n",
    "\n",
    "rdn_search.fit(X_tr,y_tr_b)\n",
    "y_pred_b = rdn_search.predict(X_tr)\n",
    "accuracy_score(y_tr_b, y_pred_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023026BBE748>, 'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023026BBE710>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdn_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### (c) Train a Logistic Regression (search teh best hyper-parameters) and compare its performance with SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8385935769656699\n",
      "Best Penalty: l1\n",
      "Best C: 2.3946339367881464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C=uniform(loc=0, scale=4)\n",
    "param_grid = dict(C=C, penalty=penalty)\n",
    "clf_lr = RandomizedSearchCV(LogisticRegression(solver = 'liblinear'), param_grid, cv = 5, random_state=42, n_iter=50, scoring='accuracy')\n",
    "\n",
    "best_model = clf_lr.fit(X_tr, y_tr_b)\n",
    "y_pred_lr = clf_lr.predict(X_tr)\n",
    "print('Accuracy:', accuracy_score(y_tr_b, y_pred_lr))\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a result, SVC has a better performance than Logistic regression dose in this case\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
